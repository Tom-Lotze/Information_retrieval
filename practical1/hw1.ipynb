{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 (Total Points: 175)\n",
    "\n",
    "\n",
    "\n",
    "Learning Goals:\n",
    "- Learn how to load a dataset and process it.\n",
    "- Learn how to implement several IR methods (TFIDF, BM25, QL) and understand their weaknesses & strengths.\n",
    "- Learn how to evaluate IR methods\n",
    "\n",
    "\n",
    "**NOTE 1**: Only the code (`TODO: Implement this!` denotes these sections) is graded. The 'theory' questions in this assignment serve as a preparation for the exam and to facilitate a deeper understanding of the course content. These questions (denoted by `TODO: Answer this!`) have no points assigned to them, but **need** to be filled out before submission.  \n",
    "\n",
    "**NOTE 2**: You can use the `nltk`, `numpy` and `matplotlib` libraries here. Other libraries, e.g., `gensim` or `scikit-learn`, may not be used. \n",
    "\n",
    "**NOTE 3**: The notebook you submit has to have the student ids, seperated by underscores (E.g., `12341234_12341234_12341234.ipynb`). \n",
    "\n",
    "**NOTE 4**: Make sure to check that your notebook runs before submission. A quick way to do this is to restart the kernel and run all the cells.  \n",
    "\n",
    "---\n",
    "Additional Resources: \n",
    "-  Sections 2.3, 4.1, 4.2, 4.3, 5.3, 5.6, 5.7, 6.2, 7, 8 of [Search Engines: Information Retrieval in Practice](https://ciir.cs.umass.edu/downloads/SEIRiP.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/berend/miniconda3/envs/ir1-hw1/lib/python3.6/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "# TODO: Ensure that no additional library is imported in the notebook. \n",
    "# TODO: Only the standard library and the following libraries are allowed:\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "from functools import partial\n",
    "\n",
    "import nltk\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML\n",
    "from IPython.html import widgets\n",
    "from collections import namedtuple, defaultdict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Text Processing (20 points)\n",
    "\n",
    "In this section, we will load the dataset and learn how to clean up the data to make it usable for an IR system. \n",
    "\n",
    "We are using the [CACM dataset](http://ir.dcs.gla.ac.uk/resources/test_collections/cacm/), which is a small, classic IR dataset, composed of a collection of titles and abstracts from the journal CACM. It comes with relevance judgements for queries, so we can evaluate our IR system. \n",
    "\n",
    "The following cell downloads the dataset and unzips it to a local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(folder_path = \"./datasets/\"):\n",
    "    \n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    file_location = os.path.join(folder_path, \"cacm.zip\")\n",
    "    \n",
    "    # download file if it doesn't exist\n",
    "    if not os.path.exists(file_location):\n",
    "        \n",
    "        url = \"https://surfdrive.surf.nl/files/index.php/s/M0FGJpX2p8wDwxR/download\"\n",
    "\n",
    "        with open(file_location, \"wb\") as handle:\n",
    "            print(f\"Downloading file from {url} to {file_location}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            for data in tqdm(response.iter_content()):\n",
    "                handle.write(data)\n",
    "            print(\"Finished downloading file\")\n",
    "    \n",
    "    if not os.path.exists(os.path.join(folder_path, \"train.txt\")):\n",
    "        \n",
    "        # unzip file\n",
    "        with zipfile.ZipFile(file_location, 'r') as zip_ref:\n",
    "            zip_ref.extractall(folder_path)\n",
    "        \n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a brief description of each file in the dataset by looking at the README file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in this directory with sizes:\r\n",
      "          0 Jun 19 21:01 README\r\n",
      "\r\n",
      "    2187734 Jun 19 20:55 cacm.all              text of documents\r\n",
      "        626 Jun 19 20:58 cite.info             key to citation info\r\n",
      "                                                (the X sections in cacm.all)\r\n",
      "       2668 Jun 19 20:55 common_words           stop words used by smart\r\n",
      "       2194 Jun 19 20:55 make_coll*             shell script to make collection\r\n",
      "       1557 Jun 19 20:55 make_coll_term*        ditto (both useless without\r\n",
      "                                                smart system)\r\n",
      "       9948 Jun 19 20:55 qrels.text             relation giving\r\n",
      "                                                    qid did 0 0\r\n",
      "                                                to indicate dument did is\r\n",
      "                                                relevant to query qid\r\n",
      "      13689 Jun 19 20:55 query.text             Original text of the query\r\n"
     ]
    }
   ],
   "source": [
    "##### Read the README file \n",
    "!cat ./datasets/README\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "We are interested in 4 files:\n",
    "- `cacm.all` : Contains the text for all documents. Note that some documents do not have abstracts available. \n",
    "- `query.text` : The text of all queries\n",
    "- `qrels.text` : The relevance judgements\n",
    "- `common_words` : A list of common words. This may be used as a collection of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".I 1\r\n",
      ".T\r\n",
      "Preliminary Report-International Algebraic Language\r\n",
      ".B\r\n",
      "CACM December, 1958\r\n",
      ".A\r\n",
      "Perlis, A. J.\r\n",
      "Samelson,K.\r\n",
      ".N\r\n",
      "CA581203 JB March 22, 1978  8:28 PM\r\n",
      ".X\r\n",
      "100\t5\t1\r\n",
      "123\t5\t1\r\n",
      "164\t5\t1\r\n",
      "1\t5\t1\r\n",
      "1\t5\t1\r\n",
      "1\t5\t1\r\n",
      "205\t5\t1\r\n",
      "210\t5\t1\r\n",
      "214\t5\t1\r\n",
      "1982\t5\t1\r\n",
      "398\t5\t1\r\n",
      "642\t5\t1\r\n",
      "669\t5\t1\r\n",
      "1\t6\t1\r\n",
      "1\t6\t1\r\n",
      "1\t6\t1\r\n",
      "1\t6\t1\r\n",
      "1\t6\t1\r\n",
      "1\t6\t1\r\n",
      "1\t6\t1\r\n",
      "1\t6\t1\r\n",
      "1\t6\t1\r\n",
      "1\t6\t1\r\n",
      "165\t6\t1\r\n",
      "196\t6\t1\r\n",
      "196\t6\t1\r\n",
      "1273\t6\t1\r\n",
      "1883\t6\t1\r\n",
      "324\t6\t1\r\n",
      "43\t6\t1\r\n",
      "53\t6\t1\r\n",
      "91\t6\t1\r\n",
      "410\t6\t1\r\n",
      "3184\t6\t1\r\n"
     ]
    }
   ],
   "source": [
    "##### The first 45 lines of the CACM dataset forms the first record\n",
    "# We are interested only in 3 fields. \n",
    "# 1. the '.I' field, which is the document id\n",
    "# 2. the '.T' field (the title) and\n",
    "# 3. the '.W' field (the abstract, which may be absent)\n",
    "!head -45 ./datasets/cacm.all\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now, write a function to read in the `cacm.all` file. Note that each document has a variable number of lines. The `.I` field denotes a new document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! (4 points)\n",
    "def read_cacm_docs(root_folder = \"./datasets/\"):\n",
    "    \"\"\"\n",
    "        Reads in the CACM documents. The dataset is assumed to be in the folder \"./datasets/cacm\" be default\n",
    "        Returns: A list of 2-tuples: (doc_id, document), where 'document' is a single string created by \n",
    "            appending the title and abstract (seperated by a \"\\n\"). \n",
    "            In case the record doesn't have an abstract, the document is composed only by the title\n",
    "    \"\"\"\n",
    "    \n",
    "    filepath = os.path.join(root_folder, 'cacm.all')\n",
    "    doc_ids = []\n",
    "    documents = []\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        docs = f.read().split('.I ')[1:]\n",
    "    \n",
    "    for doc in docs:\n",
    "        lines = doc.split('\\n')\n",
    "        doc_id = int(lines[0])\n",
    "        title = lines[lines.index('.T')+1]\n",
    "\n",
    "        if '.W' in lines:\n",
    "            start = lines.index('.W')+1\n",
    "            end   = lines.index('.B')\n",
    "            abstract = '\\n'+'  '.join(lines[start:end])\n",
    "\n",
    "        else:\n",
    "            abstract = ''\n",
    "        \n",
    "        doc_ids.append(doc_id)\n",
    "        documents.append(title + abstract)\n",
    "        \n",
    "    return list(zip(doc_ids, documents))\n",
    "\n",
    "docs = read_cacm_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "assert len(docs) == 3204, \"There should be exactly 3024 documents\"\n",
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next, let us read the queries. They are formatted similarly: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".I 1\r\n",
      ".W\r\n",
      " What articles exist which deal with TSS (Time Sharing System), an\r\n",
      "operating system for IBM computers?\r\n",
      ".N\r\n",
      " 1. Richard Alexander, Comp Serv, Langmuir Lab (TSS)\r\n",
      " \r\n",
      ".I 2\r\n",
      ".W\r\n",
      " I am interested in articles written either by Prieve or Udo Pooch\r\n",
      ".A\r\n",
      "Prieve, B.\r\n",
      "Pooch, U.\r\n",
      ".N\r\n",
      " 2. Richard Alexander, Comp Serv, Langmuir Lab (author = Pooch or Prieve)\r\n"
     ]
    }
   ],
   "source": [
    "##### The first 15 lines of 'query.text' has 2 queries\n",
    "# We are interested only in 2 fields. \n",
    "# 1. the '.I' - the query id\n",
    "# 2. the '.W' - the query\n",
    "!head -15 ./datasets/query.text\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now, write a function to read in this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! (3 points)\n",
    "def read_queries(root_folder = \"./datasets/\"):\n",
    "    \"\"\"\n",
    "        Reads in the CACM queries. The dataset is assumed to be in the folder \"./datasets/\" be default\n",
    "        Returns: A list of 2-tuples: (query_id, query)\n",
    "    \"\"\"\n",
    "    \n",
    "    queries   = []\n",
    "    filepath = os.path.join(root_folder, 'query.text')\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        queries_unprocessed = f.read().split('.I')[1:]\n",
    "        \n",
    "    for q in queries_unprocessed:\n",
    "        lines = q.split('\\n')\n",
    "        \n",
    "        query_id = int(lines[0])\n",
    "        \n",
    "        start = lines.index('.W')+1\n",
    "        end   = lines.index('.N') if '.A' not in lines else lines.index('.A')\n",
    "        query = ' '.join(lines[start:end])\n",
    "        \n",
    "        queries.append((query_id, query))\n",
    "        \n",
    "    return queries\n",
    "    \n",
    "    \n",
    "queries = read_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "assert len(queries) == 64 and all([q[1] is not None for q in queries]), \"There should be exactly 64 queries\"\n",
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Read in the stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\r\n",
      "about\r\n",
      "above\r\n",
      "accordingly\r\n",
      "across\r\n",
      "after\r\n",
      "afterwards\r\n",
      "again\r\n",
      "against\r\n",
      "all\r\n"
     ]
    }
   ],
   "source": [
    "!head ./datasets/common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! (3 points)\n",
    "def load_stopwords(root_folder = \"./datasets\"):\n",
    "    \"\"\"\n",
    "    Load the stopwords\n",
    "    Output: A set of stopwords\n",
    "    \"\"\"\n",
    "    \n",
    "    filepath = os.path.join(root_folder, 'common_words')\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        stopwords = set(f.read().split())\n",
    "    \n",
    "    return stopwords\n",
    "\n",
    "stopwords = load_stopwords()\n",
    "assert len(stopwords) == 428"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "We can now write some basic text processing functions. A first step is to tokenize the text. You may use any tokenizer available in the `nltk` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/berend/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement this! (5 points)\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "        Tokenize the text. \n",
    "        Input: text - a string\n",
    "        Output: a list of tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    return nltk.tokenize.word_tokenize(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "text = \"the quick brown fox jumps over the lazy dog\"\n",
    "tokens = tokenize(text)\n",
    "print(tokens)\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Answer the following questions*: \n",
    "- Why is stemming necessary, in particular for IR?\n",
    "    - TODO: Answer this!\n",
    "    - Stemming removes unnecessary information captures in suffixed and affixes, and keeps the information embedded in the stem. It makes the IR system more flexible and the IR task simpler as different word forms can be recognized as the same query word (which is stemmed as well). \n",
    "- Is there any setting (domain, scenario, etc) in which stemming can hurt performance? Illustrate with an example\n",
    "    - *TODO: Answer this!*\n",
    "    - Stemmers may generate false positives by overstemming (words that are stemmed to the same root while they should not have been), an example: university, universal and universe are all stemmed to \"univers\" (source: https://en.wikipedia.org/wiki/Stemming#Error_metrics). \n",
    "    - A domain which could suffer from errors in stemming would be a collection of medical texts. In medical texts, words with a Greek and Latin origin frequently occur. These words are conjugated differently than according to traditional English grammar. Example: Alumnus -> alumnu, alumni -> alumni, alumna -> alumna, this is an example of understemming. The word should have been stemmed to the same root, but they are not, as they do not follow standard English grammar. \n",
    "    Two different words may have the same without having the same semantical meaning. An example would be: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to stem tokens. Again, you can use the `nltk` library for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! (5 points)\n",
    "def stem_token(token):\n",
    "    \"\"\"\n",
    "        Stem the given token, using any stemmer available from the nltk library\n",
    "        Input: a single token\n",
    "        Output: the stem of the token\n",
    "    \"\"\"\n",
    "    \n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    \n",
    "    return stemmer.stem(token)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazi', 'dog']\n",
      "['caress', 'fli', 'die', 'mule', 'deni', 'die', 'agre', 'own', 'humbl', 'size', 'meet', 'state', 'siez', 'item', 'sensat', 'tradit', 'refer', 'colon', 'plot']\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "print([stem_token(t) for t in tokens])\n",
    "tokens_ = [\n",
    "    'caresses', 'flies', 'dies', 'mules', 'denied',\n",
    "    'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "    'meeting', 'stating', 'siezing', 'itemization',\n",
    "    'sensational', 'traditional', 'reference', 'colonizer',\n",
    "    'plotted']\n",
    "print([stem_token(t) for t in tokens_])\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Answer the following questions*: \n",
    "- Another processing step (not done here) is to use n-grams. Illustrate why you would want to use n-grams in IR with an example.  \n",
    "    - *TODO: Answer this!*\n",
    "    - Unigram models assume that words are independent from their neighbours. However, in natural language this is rarely the case. Using N-grams can enable us to capture dependencies in word sequences. An example we have seen in class is the query \"Paris Hilton\". If we take this query as two separate words, we may find a Hilton hotel in Paris. However, when we consider the bi-gram \"Paris Hilton\", it is clear that we are looking for the celebrity Paris Hilton. \n",
    "- Usage of n-grams exacerbates some problems ex. in bi-gram language models. What is this problem? Suggest one solution \n",
    "    - *TODO: Answer this!*\n",
    "    - When considering bi-grams rather than unigrams, the probability of encountering a new (unseen) bi-gram is higher than when considering unigrams. A solution could be to use laplace-smoothing, or backoff and interpolation (if bi-gram is unseen, try using the unigrams). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "The following function puts it all together. Given a string, it tokenizes it, and processes it according to the flags that you set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Putting it all together\n",
    "def process_text(text, stem=False, remove_stopwords=False, lowercase_text=False):\n",
    "    \n",
    "    tokens = []\n",
    "    for token in tokenize(text):\n",
    "        if remove_stopwords and token.lower() in stopwords:\n",
    "            continue\n",
    "        if stem:\n",
    "            token = stem_token(token)\n",
    "        if lowercase_text:\n",
    "            token = token.lower()\n",
    "        tokens.append(token)\n",
    "\n",
    "    return tokens\n",
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create two sets of pre-processed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this configuration:\n",
    "# Don't preprocess the text, except to tokenize \n",
    "config_1 = {\n",
    "  \"stem\": False,\n",
    "  \"remove_stopwords\" : False,\n",
    "  \"lowercase_text\": True\n",
    "} \n",
    "\n",
    "\n",
    "# In this configuration:\n",
    "# Preprocess the text: stem and remove stopwords\n",
    "config_2 = {\n",
    "  \"stem\": True,\n",
    "  \"remove_stopwords\" : True,\n",
    "  \"lowercase_text\": True, \n",
    "} \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now process the documents and queries according to the configuration specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "doc_repr_1 = []\n",
    "doc_repr_2 = []\n",
    "for (doc_id, document) in docs:\n",
    "    doc_repr_1.append((doc_id, process_text(document, **config_1)))\n",
    "    doc_repr_2.append((doc_id, process_text(document, **config_2)))\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--- \n",
    "\n",
    "## Section 2: Indexing (10 points)\n",
    "\n",
    "\n",
    "A retrieval function usually takes in a query document pair, and scores a query against a document.  Our document set is quite small - just a few thousand documents. However, consider a web-scale dataset with a few million documents. In such a scenario, it would become infeasible to score every query and document pair. In such a case, we can build an inverted index. From Wikipedia:\n",
    "\n",
    "> ... , an inverted index (also referred to as a postings file or inverted file) is a database index storing a mapping from content, such as words or numbers, to its locations in a table, .... The purpose of an inverted index is to allow fast full-text searches, at a cost of increased processing when a document is added to the database. ...\n",
    "\n",
    "\n",
    "Consider a simple inverted index, which maps from word to document. This can improve the performance of a retrieval system significantly. In this assignment, we consider a *simple* inverted index, which maps a word to a set of documents. In practice, however, more complex indices might be used.  \n",
    "\n",
    "\n",
    "### Building an index\n",
    "\n",
    "A retrieval function usually takes in a query document pair, and scores a query against a document.  Our document set is quite small - just a few thousand documents. However, consider a web-scale dataset with a few million documents. In such a scenario, it would become infeasible to score every query and document pair. In such a case, we can build an inverted index. From Wikipedia:\n",
    "\n",
    "> ... , an inverted index (also referred to as a postings file or inverted file) is a database index storing a mapping from content, such as words or numbers, to its locations in a table, .... The purpose of an inverted index is to allow fast full-text searches, at a cost of increased processing when a document is added to the database. ...\n",
    "\n",
    "\n",
    "Consider a simple inverted index, which maps from word to document. This can improve the performance of a retrieval system significantly. In this assignment, we consider a *simple* inverted index, which maps a word to a set of documents. In practice, however, more complex indices might be used.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this assignment we will be using an index created in memory, since our dataset is tiny. To get started, build a simple index that maps simply counts the number of tokens present in a document. This index  is built using a python dictionary.\n",
    "\n",
    "*Answer the following questions*:\n",
    "- What is the time complexity of retrieving a list of documents from a python `dict` object? \n",
    "    - *TODO: Answer this!* \n",
    "    - Since Python's dictionaries use hash tables, a search of documents would have an average time complexity $O(1)$. \n",
    "- Consider the case with a 10 million documents. What is the time complexity of retrieval with an inverted index (assuming you can fit the entire index in memory)? (Hint: Consider length of a query $|q|$) \n",
    "    - *TODO: Answer this!*\n",
    "    - First: q lookups in inverted index: $O(|q|)$. This yields k document IDs. Looking up the documents has a complexity of $k O(1)$. $kO(1) + O(|q|) = O(|q|)$. \n",
    "- For a large enough collection, we cannot store an index in memory. How is this tackled in practice (briefly explain)? Comment on the time complexity. \n",
    "    - *TODO: Answer this!*\n",
    "    - The inverted list is split in several blocks that do fit in memory. Say we need B blocks to fit the entire list in memory, we would have to look up the query B times more.\n",
    "- Mention a use-case in which a simple index (from word -> doc_id) might not suffice anymore. How would you modify the index to suit this use-case (if you can!)  \n",
    "    - *TODO: Answer this!*\n",
    "    - At some point, we migth want to index very large documents (e.g. books). Then, the fact that a term occurs in the document does not make it relevant per se. We can modify the index to contain counts or relative frequencies of the terms.\n",
    "    \n",
    "    \n",
    "Now, implement a function to build an index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! 10 points\n",
    "def build_tf_index(documents):\n",
    "    \"\"\"\n",
    "    Build an inverted index (with counts). The output is a dictionary which takes in a token\n",
    "    and returns a list of (doc_id, count) where 'count' is the count of the 'token' in 'doc_id'\n",
    "    Input: a list of documents - (doc_id, tokens) \n",
    "    Output: An inverted index. [token] -> [(doc_id, token_count)]\n",
    "    \"\"\"\n",
    "    \n",
    "    index = defaultdict(list)\n",
    "    \n",
    "    for doc_id, doc in documents:\n",
    "        tokens, counts = np.unique(doc, return_counts=True)\n",
    "    \n",
    "        for token, count in zip(tokens, counts):\n",
    "            index[token].append((doc_id, count))\n",
    "   \n",
    "    return index\n",
    " \n",
    "# Create the 2 indices\n",
    "tf_index_1 = build_tf_index(doc_repr_1)\n",
    "tf_index_2 = build_tf_index(doc_repr_2)\n",
    "\n",
    "# This function returns the correct index \n",
    "def get_index(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {\n",
    "        1: tf_index_1,\n",
    "        2: tf_index_2\n",
    "    }[index_set]\n",
    "\n",
    "# This function correctly pre-processes the text given the index set\n",
    "def preprocess_query(text, index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    if index_set == 1:\n",
    "        return process_text(text, **config_1)\n",
    "    elif index_set == 2:\n",
    "        return process_text(text, **config_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Section 3: Retrieval  (80 points)\n",
    "\n",
    "Now that we have cleaned and processed our dataset, we can start building simple IR systems. \n",
    "\n",
    "For now, we consider *simple* IR systems, which involve computing scores from the tokens present in the document/query. More advanced methods are covered in later assignments.\n",
    "\n",
    "We will implement the following methods in this section:\n",
    "- TF-IDF\n",
    "- BM25\n",
    "- Query Likelihood Models\n",
    "\n",
    "--- \n",
    "\n",
    "### Ranking functions\n",
    "\n",
    "\n",
    "Probably the simplest IR model is the Bag of Words (BOW) model. Implement a function that scores a query against a document using this model.   \n",
    "\n",
    "Note that you can use either the count of the token or 'binarize' it i.e set the value equal to 1 if the token appears.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Make sure you use the `get_index` function to retrieve the correct index, and call `preprocess_query` with the correct index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! 10 points\n",
    "def bow_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query. \n",
    "        Note #1: You have to use the `get_index` function created in the previous cells\n",
    "        Note #2: You can binarize the counts if you wish to\n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    \n",
    "    index = get_index(index_set)    \n",
    "    query = preprocess_query(query, index_set)\n",
    "\n",
    "    # get query_terms and counts\n",
    "    query_terms, query_counts = np.unique(query, return_counts=True)\n",
    "        \n",
    "    # init empty vectors\n",
    "    vectors = defaultdict(lambda:[0] * len(query_counts))\n",
    "    \n",
    "    # init scores dict\n",
    "    scores = {}\n",
    "    \n",
    "    # loop over query terms\n",
    "    for i, term in enumerate(query_terms):\n",
    "        for doc_id, c in index[term]:\n",
    "            # set vector entry to term frequency in document\n",
    "            vectors[doc_id][i] = c * query_counts[i]\n",
    "    \n",
    "    # calculate cos similarity\n",
    "    for doc_id in vectors.keys():\n",
    "        scores[doc_id] = np.dot(vectors[doc_id], query_counts) / (np.linalg.norm(vectors[doc_id])*np.linalg.norm(query_counts))\n",
    "    \n",
    "    # set doc scores for docs without query terms to 0 \n",
    "    for doc_id, _ in docs:\n",
    "        if doc_id not in scores.keys():\n",
    "            scores[doc_id] = 0\n",
    "    \n",
    "    # back to list and sort\n",
    "    scores = [(k,v) for k,v in scores.items()]\n",
    "    scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer the following questions*: \n",
    "- The BOW model is might not be a good choice for use in IR. Why? \n",
    "    - BOW assumes independence between words, and also neglects word order. However, word order might have a significant effect on the meaning and intent of the query, and we might lose information if we disregard the word order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Results:\n",
      "Rank 0(1.0): ALGOL Sub-Committee Report - Extensions...\n",
      "Rank 1(1.0): The Use of Computers in Engineering Classroom Inst...\n",
      "Rank 2(1.0): Report on a Conference of University Computing Cen...\n",
      "Rank 3(1.0): Report on the Algorithmic Language ALGOL 60...\n",
      "Rank 4(1.0): SMALGOL-61\\nPrior to and during the 1961 Western J...\n",
      "CPU times: user 3.35 ms, sys: 1.39 ms, total: 4.75 ms\n",
      "Wall time: 3.77 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "####\n",
    "docs_by_id = dict(docs)\n",
    "def print_results(docs, len_limit=50):    \n",
    "    for i, (doc_id, score) in enumerate(docs):\n",
    "        doc_content = docs_by_id[doc_id].strip().replace(\"\\n\", \"\\\\n\")[:len_limit] + \"...\"\n",
    "        print(f\"Rank {i}({score:.2}): {doc_content}\")\n",
    "\n",
    "test_bow = bow_search(\"report\", index_set=1)[:5]\n",
    "print(f\"BOW Results:\")\n",
    "print_results(test_bow)\n",
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we implement the tf-idf scoring functions, let's first write a function to compute the document frequencies of all words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! (5 points)\n",
    "def compute_df(documents):\n",
    "    \"\"\"\n",
    "        Compute the document frequency of all terms in the vocabulary\n",
    "        Input: A list of documents\n",
    "        Output: A dictionary with {token: document frequency)\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_freq = defaultdict(int)\n",
    "    \n",
    "    for document in documents:\n",
    "        for token in set(document):\n",
    "            doc_freq[token] += 1\n",
    "\n",
    "    return doc_freq\n",
    "            \n",
    "            \n",
    "        \n",
    "# get the document frequencies of each document\n",
    "df_1 = compute_df([d[1] for d in doc_repr_1])\n",
    "df_2 = compute_df([d[1] for d in doc_repr_2])\n",
    "\n",
    "def get_df(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {\n",
    "        1: df_1,\n",
    "        2: df_2\n",
    "    }[index_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement a function that computes a tf-idf score given a query.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! 10 points\n",
    "def tfidf_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using tf-idf. \n",
    "        Note #1: You have to use the `get_index` (and the `get_df`) function created in the previous cells\n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    df = get_df(index_set)\n",
    "    query = preprocess_query(query, index_set)\n",
    "    N = len(docs)\n",
    "    \n",
    "    # get query terms and their counts \n",
    "    query_terms, query_counts = np.unique(query, return_counts=True)\n",
    "    \n",
    "    # define empty vectors\n",
    "    vectors = defaultdict(lambda:[0] * len(query_counts))\n",
    "    \n",
    "    #init score dict\n",
    "    scores = {}\n",
    "\n",
    "    # calculate the query vector\n",
    "    query_vector = [c * np.log(N/df[term]) if df[term] != 0 else 0 for c, term in zip(query_counts, query_terms)]\n",
    "    \n",
    "    # loop over query terms and docs in inverted index\n",
    "    for i, term in enumerate(query_terms):\n",
    "        for doc_id, c in index[term]:\n",
    "            # if term does not occur in doc, vector entry is 0\n",
    "            if df[term] == 0:\n",
    "                vectors[doc_id][i] = 0\n",
    "            # else, vector entry is tf-idf\n",
    "            else:\n",
    "                vectors[doc_id][i] = c * query_counts[i] * np.log(N/df[term])\n",
    "    \n",
    "    # for each doc vector calculate cos similarity with query vector\n",
    "    for doc_id in vectors.keys():\n",
    "        scores[doc_id] = np.dot(vectors[doc_id], query_vector) / (np.linalg.norm(vectors[doc_id]) * np.linalg.norm(query_vector))\n",
    "    \n",
    "    # if doc does not contain query terms, set score to 0 \n",
    "    for doc_id, _ in docs:\n",
    "        if doc_id not in scores.keys():\n",
    "            scores[doc_id] = 0\n",
    "    \n",
    "    # back to list and sort\n",
    "    scores = [(k,v) for k,v in scores.items()]\n",
    "    scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Results:\n",
      "Rank 0(1.0): The State of Computer Oriented Curricula in Busine...\n",
      "Rank 1(1.0): The Technology of Computer Center Management: A\\nM...\n",
      "Rank 2(0.98): Rejuvenating Experimental Computer Science\\nThis r...\n",
      "Rank 3(0.95): Computational Linguistics in a Ph.D. Computer Scie...\n",
      "Rank 4(0.9): Information Science in a Ph.D. Computer Science Pr...\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "test_tfidf = tfidf_search(\"report science\", index_set=1)[:5]\n",
    "print(f\"TFIDF Results:\")\n",
    "print_results(test_tfidf)\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer the following questions*: \n",
    "- It is generally not advisable to use the naive version of tf-idf. Why?\n",
    "    - *TODO: Answer this!*\n",
    "    - The naive version of tf-idf does not take into account the document length, which might become problematic if some of the documents become very long (e.g. books), since the query terms are more likely to appear more often in those long documents. Furthermore, if the query term does not occur in any of the documents, we encounter divisions by 0.  \n",
    "- Illustrate with an example why using a sublinear scaling for TF is preferable in some cases.  \n",
    "    - *TODO: Answer this!*\n",
    "    - Intuitively, we can explain this by the fact that the 100th occurence of a term in a document is not as significant as the first or second time. In other words, by using a sublinear scaling we decrease the marginal significance of term occurences when the frequency increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "*Answer the following questions*: \n",
    "- An alternative way to compute a query<>document score is to vectorize both the query and document (where each dimension corresponds to a token), and compute a score. The score can be computed using a dot product between the query and the document vectors. Why is the cosine similary function a better choice, particularly in IR? \n",
    "    - **Answer**\n",
    "    - The cosine similarity is preferred over the dot product, as the cosine similarity is normalized. In other words, the cosine similarity only cares about the angle of difference between the vectors, whereas the dot product also cares about the magnitude. \n",
    "- What is the time complexity of a search if we are using the vector space method mentioned in the previous question? What is the time complexity if we're using an index (assume that it fits in memory)? Assume $N$ is the number of documents and $|q|$ is the length of a query. \n",
    "    - **Answer**\n",
    "    - Dot product algorithm: vectors A and B have length $|q|$, we multiply each $a_i$ and $b_i$, resulting in $|q|$ multiplications. Moreover, we add sum over all the previously computed products $a_i b_i$, which requires another $|q| - 1$ steps. In total, this would result in a time complexity of $O(|q|) + O(|q|) = O(|q|)$ per documents, with N documents: $N O(|q|) = O(N|q|)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "#### Query Likelihood Models\n",
    "\n",
    "In this section you will implement a simple query likelihood model. \n",
    "\n",
    "First, let use implement a naive version of a QL model, assuming a multinomial unigram language model (with a uniform prior over the documents). \n",
    "\n",
    "**Note:** Make sure you use the `get_index` function to retrieve the correct index, and call `preprocess_query` with the correct index!\n",
    "\n",
    "--- \n",
    "\n",
    "*Answer the following questions*: \n",
    "- Write down the formula for computing the query likelihood, assuming a multinomial unigram language model. \n",
    "    -     $p(d|q) = p(q|d)p(d)/p(q)$\n",
    "    \n",
    "    $p(q)$ is constant and $p(d)$ is assumed to be uniform. \n",
    "    \n",
    "    Hence: $p(d|q) = p(q|d) = \\prod_{i=1}^{|q|}p(t_{i}|d) = \\prod_{i=1}^{|q|} \\frac{c(t_{i},d)}{dl(d)}$\n",
    " \n",
    " \n",
    "- What problem does this naive method have? Suggest a simple way to fix it.\n",
    "    - The problem with this naive method is that the likelihood of a document will be 0 if one of the terms does not appear in the document. So, if $c(t_{i},d) = 0$, $p(d|q) = p(q|d) = 0$, whereas other words in the query might appear and a score of 0 would thus be inaccurate. A simple way to fix this is by implementing a smoothing method. The code below implements the Jelinek-Mercer smoothing method. This  method allows interpolation between document frequency and collection frequency. So instead of fully relying on the frequency of a term in a document, we also take into account how often the term occurs in the collection of documents. The hyperparameters $\\alpha$ decides the weight assigned to both frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "def doc_lengths(documents):\n",
    "    doc_lengths = {doc_id:len(doc) for (doc_id, doc) in documents}\n",
    "    return doc_lengths\n",
    "\n",
    "doc_lengths_1 = doc_lengths(doc_repr_1)\n",
    "doc_lengths_2 = doc_lengths(doc_repr_2)\n",
    "\n",
    "def get_doc_lengths(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {\n",
    "        1: doc_lengths_1,\n",
    "        2: doc_lengths_2\n",
    "    }[index_set]\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Implement this! 15 points\n",
    "def naive_ql_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using a naive QL model. \n",
    "        Note #1: You have to use the `get_index` (and get_doc_lengths) function created in the previous cells\n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    \n",
    "    index = get_index(index_set)\n",
    "    doc_len = get_doc_lengths(index_set)\n",
    "    query = preprocess_query(query, index_set)\n",
    "    \n",
    "    # get query counts and terms to calculate KL divergence\n",
    "    query_terms, query_counts = np.unique(query, return_counts=True)\n",
    "    query_len = sum(query_counts)\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    # scores start at 0 \n",
    "    scores = defaultdict(lambda:0)\n",
    "    \n",
    "    # loop over query terms \n",
    "    for i, term in enumerate(query_terms):\n",
    "        # compute the likelihood of the term given the query\n",
    "        term_llh_query = query_counts[i] / query_len\n",
    "        for doc_id, c in index[term]:\n",
    "            # compute the likelihood of the term given the doc\n",
    "            term_llh_doc = c / doc_len[doc_id]\n",
    "            # calculate the part of KL Divergence for this term in query and this doc, sum over terms\n",
    "            scores[doc_id] += query_counts[i] * term_llh_query * np.log(term_llh_query / term_llh_doc)\n",
    "    \n",
    "    # inverse KL divergence, epsilon to avoid division by 0\n",
    "    for doc_id in scores.keys():\n",
    "        scores[doc_id] = 1 / (scores[doc_id] + epsilon)\n",
    "    \n",
    "    # for each document that did not have any of the query terms, set score to 0\n",
    "    for doc_id, _ in docs:\n",
    "        if doc_id not in scores.keys():\n",
    "            scores[doc_id] = float(0)\n",
    "    \n",
    "    # back to list and sort\n",
    "    scores = [(k,v) for k,v in scores.items()]\n",
    "    scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Results:\n",
      "Rank 0(0.62): ALGOL Sub-Committee Report - Extensions...\n",
      "Rank 1(0.62): A Report Writer For COBOL...\n",
      "Rank 2(0.62): A CRT Report Generating System...\n",
      "Rank 3(0.56): Supplement to the ALGOL 60 Report...\n",
      "Rank 4(0.51): Report on the Algorithmic Language ALGOL 60...\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "test_naiveql = naive_ql_search(\"report\", index_set=1)[:5]\n",
    "print(f\"TFIDF Results:\")\n",
    "print_results(test_naiveql)\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement a (slightly more) complex QL model. This model should 'fix' the issue with the previous method. If your model requires hyperparameters, set a reasonable value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! 20 points\n",
    "def ql_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using a appropriate QL model. \n",
    "        Note #1: You have to use the `get_index` (and get_doc_lengths) function created in the previous cells\n",
    "        Note #2: You might have to create some variables beforehand and use them in this function\n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    doc_len = get_doc_lengths(index_set)\n",
    "    query = preprocess_query(query, index_set)\n",
    "    \n",
    "    # total number of terms in collection for smoothing\n",
    "    C = sum(doc_len.values())\n",
    "    \n",
    "    # get query counts and terms to calculate KL divergence\n",
    "    query_terms, query_counts = np.unique(query, return_counts=True)\n",
    "    query_len = sum(query_counts)\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    # scores start at 0\n",
    "    scores = defaultdict(lambda:0)\n",
    "\n",
    "    freq_dict = dict()\n",
    "    for i, term in enumerate(query_terms):\n",
    "        # calculate collection frequency of term for smoothing\n",
    "        freq_dict[term] = sum([c for i,c in index[term]])\n",
    "        # compute term likelihood given the query\n",
    "        term_llh_query = query_counts[i] / query_len\n",
    "        for doc_id, c in index[term]:\n",
    "            # calculate p(t|d) with Jelinek Mercer smoothing (interpolation)\n",
    "            ptd = alpha * c / doc_len[doc_id] + (1 - alpha) * freq_dict[term] / C\n",
    "            # calculate the part of KL Divergence for this term in query and this doc, sum over terms\n",
    "            scores[doc_id] += query_counts[i] * term_llh_query * np.log(term_llh_query / ptd)\n",
    "\n",
    "    # Inverse KL divergence for ranking, add epsilon to avoid division by 0\n",
    "    for doc_id in scores.keys():\n",
    "        scores[doc_id] = 1 / (scores[doc_id] + epsilon)\n",
    "    \n",
    "    # set score to 0 for each doc without any query terms\n",
    "    for doc_id, _ in docs:\n",
    "        if doc_id not in scores.keys():\n",
    "            scores[doc_id] = float(0)\n",
    "    \n",
    "    # back to list and sort\n",
    "    scores = [(k,v) for k,v in scores.items()]\n",
    "    scores = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0(0.51): ALGOL Sub-Committee Report - Extensions...\n",
      "Rank 1(0.51): A Report Writer For COBOL...\n",
      "Rank 2(0.51): A CRT Report Generating System...\n",
      "Rank 3(0.47): Supplement to the ALGOL 60 Report...\n",
      "Rank 4(0.43): Report on the Algorithmic Language ALGOL 60...\n",
      "\n",
      "Rank 0(0.051): ALGOL Sub-Committee Report - Extensions...\n",
      "Rank 1(0.051): A Report Writer For COBOL...\n",
      "Rank 2(0.051): A CRT Report Generating System...\n",
      "Rank 3(0.047): Supplement to the ALGOL 60 Report...\n",
      "Rank 4(0.043): Report on the Algorithmic Language ALGOL 60...\n"
     ]
    }
   ],
   "source": [
    "#### Test the QL model\n",
    "alpha = 0.7\n",
    "test_ql_results = ql_search(\"report\"\n",
    "                            , index_set=1)[:5]\n",
    "print_results(test_ql_results)\n",
    "print()\n",
    "test_ql_results_long = ql_search(\"report \" * 10, index_set=1)[:5]\n",
    "print_results(test_ql_results_long)\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer the following questions*: \n",
    "- What happens to the query likelihood for long queries? What is a simple fix for this issue?\n",
    "    - *TODO: Answer this!*\n",
    "    - If the query becomes very long, the likelihood of the query diminishes, as terms $< 1$ are multiplied. In the end this leads to very low scores, possibly ~0 if the query is extremely long. This might lead to numerical instabilities, which makes the ordering of the ranking problematic. A simple fix for this would be to take the log of the probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--- \n",
    "\n",
    "#### BM25\n",
    "\n",
    "In this section, we will implement the widely used and hard to beat BM25 scoring function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! (20 points)\n",
    "k1 = 1.2\n",
    "b = 0.75\n",
    "N = len(docs)\n",
    "\n",
    "def bm25_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using BM25. \n",
    "        Note #1: You have to use the `get_index` (and `get_doc_lengths`) function created in the previous cells\n",
    "        Note #2: You might have to create some variables beforehand and use them in this function\n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    # retrieve index and doc lengths \n",
    "    index = get_index(index_set)\n",
    "    doc_lengths = get_doc_lengths(index_set)\n",
    "    dl_avg = np.mean(list(doc_lengths.values()))\n",
    "    \n",
    "    # preprocess the query\n",
    "    query = preprocess_query(query, index_set)\n",
    "    \n",
    "    # init score dict\n",
    "    scores = {}\n",
    "    \n",
    "    # get document frequencies\n",
    "    df = get_df(index_set)\n",
    "    \n",
    "    # initialize all scores at 0\n",
    "    for doc_id, _ in docs:\n",
    "        if doc_id not in scores.keys():\n",
    "            scores[doc_id] = 0\n",
    "    \n",
    "    # find relevant documents by scanning the index on the terms in the query\n",
    "    for term in query:\n",
    "        # for all the docs in which the term occurs, compute the score. \n",
    "        for doc_id, c in index[term]:\n",
    "            dl = doc_lengths[doc_id]\n",
    "            # compute score according to BM25 formula.\n",
    "            scores[doc_id] += np.log(N/df[term]) * (((k1 + 1) * c) /\n",
    "                                                    (k1 * ((1-b) + b * (dl/dl_avg)) + c))\n",
    "    # back to list and sort\n",
    "    scores = [(k,v) for k,v in scores.items()]\n",
    "    ranking = sorted(scores, key = lambda x: x[1], reverse=True)\n",
    "     \n",
    "    return ranking # this is a list of tuples, ranked on relevance (doc_id, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0(7.1): Value Orientation of Computer Science Students\\nTe...\n",
      "Rank 1(7.1): A University's Educational Program in Computer Sci...\n",
      "Rank 2(7.0): A Survey of Computer Science Offerings In Small Li...\n",
      "Rank 3(6.7): Information Science in a Ph.D. Computer Science Pr...\n",
      "Rank 4(6.6): The Practical Aspect of Computer Science Education...\n"
     ]
    }
   ],
   "source": [
    "#### Test the BM25 model\n",
    "test_bm25_results = bm25_search(\"science\", index_set=1)[:5]\n",
    "print_results(test_bm25_results)\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "*Answer the following questions*: \n",
    "- Briefly explain how the BM25 model improves upon the tf-idf model.\n",
    "    - *TODO: Answer this!*\n",
    "    - The BM25 model takes into account the relative document length and compensates for that (shorter documents are as likely to be relevant than long documents. \n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Highlighter function\n",
    "# class for results\n",
    "ResultRow = namedtuple(\"ResultRow\", [\"doc_id\", \"snippet\", \"score\"])\n",
    "# doc_id -> doc\n",
    "docs_by_id = dict((d[0], d[1]) for d in docs)\n",
    "\n",
    "def highlight_text(document, query, tol=17):\n",
    "    import re\n",
    "    tokens = tokenize(query)\n",
    "    regex = \"|\".join(f\"(\\\\b{t}\\\\b)\" for t in tokens)\n",
    "    regex = re.compile(regex, flags=re.IGNORECASE)\n",
    "    output = \"\"\n",
    "    i = 0\n",
    "    for m in regex.finditer(document):\n",
    "        start_idx = max(0, m.start() - tol)\n",
    "        end_idx = min(len(document), m.end() + tol)\n",
    "        output += \"\".join([\"...\",\n",
    "                        document[start_idx:m.start()],\n",
    "                        \"<strong>\",\n",
    "                        document[m.start():m.end()],\n",
    "                        \"</strong>\",\n",
    "                        document[m.end():end_idx],\n",
    "                        \"...\"])\n",
    "    return output.replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "def make_results(query, search_fn, index_set):\n",
    "    results = []\n",
    "    for doc_id, score in search_fn(query, index_set):\n",
    "        highlight = highlight_text(docs_by_id[doc_id], query)\n",
    "        if len(highlight.strip()) == 0:\n",
    "            highlight = docs_by_id[doc_id]\n",
    "        results.append(ResultRow(doc_id, highlight, score))\n",
    "    return results\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "The widget below allows you to play with the search functions you've written so far. This can be used, for example, to answer some of the theory questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b550a62bae34cc7b601194c075918d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set this to the function you want to test\n",
    "# this function should take in a query (string)\n",
    "# and return a sorted list of (doc_id, score) \n",
    "# with the most relevant document in the first position\n",
    "search_fn = bm25_search\n",
    "index_set = 1\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "def handle_submit(sender):\n",
    "    print(f\"Searching for: '{sender.value}'\")\n",
    "    \n",
    "    results = make_results(sender.value, search_fn, index_set)\n",
    "    \n",
    "    # display only the top 5\n",
    "    results = results[:5]\n",
    "    \n",
    "    body = \"\"\n",
    "    for idx, r in enumerate(results):\n",
    "        body += f\"<li>Document #{r.doc_id}({r.score}): {r.snippet}</li>\"\n",
    "    display(HTML(f\"<ul>{body}</ul>\"))\n",
    "    \n",
    "\n",
    "text.on_submit(handle_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Offline Evaluation (45 points)\n",
    "\n",
    "Before we jump in and implement an algorithm for retrieval, we first have to learn how to evaluate such a system. In particular, we will work with offline evaluation metrics. These metrics are computed on a dataset with known relevance judgements.\n",
    "\n",
    "Implement the following evaluation metrics. \n",
    "\n",
    "1. Precision\n",
    "2. Recall\n",
    "3. Mean Average Precision\n",
    "4. Expected Reciprocal Rank\n",
    "\n",
    "---\n",
    "*Answer the following questions*: \n",
    "- What are the main limitations of an offline evaluation?\n",
    "    - *TODO: Answer this!*\n",
    "    - Creating a test collection is very labour intensive, as we need to (practically) guarantee that everything the algorithm might come up with in the ranking is labeled in terms of relevance. This labeling should be done by humans and is therefore costly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's take a look at the `qrels.text` file, which contains the ground truth relevance scores. The relevance labels for CACM are binary - either 0 or 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 1410  0 0\r\n",
      "01 1572  0 0\r\n",
      "01 1605  0 0\r\n",
      "01 2020  0 0\r\n",
      "01 2358  0 0\r\n",
      "02 2434  0 0\r\n",
      "02 2863  0 0\r\n",
      "02 3078  0 0\r\n",
      "03 1134  0 0\r\n",
      "03 1613  0 0\r\n"
     ]
    }
   ],
   "source": [
    "!head ./datasets/qrels.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is the `query_id` and the second column is the `document_id`. You can safely ignore the 3rd and 4th columns. Write a function to read in the file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this!\n",
    "def read_qrels(root_folder = \"./datasets/\"):\n",
    "    \"\"\"\n",
    "        Reads the qrels.text file. \n",
    "        Output: A dictionary: query_id -> [list of relevant documents]\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "    filepath = os.path.join(root_folder, 'qrels.text')\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    for line in lines:\n",
    "        query_id, doc_id, _, _ = line.split()\n",
    "\n",
    "        query_id = int(query_id)\n",
    "        doc_id = int(doc_id)\n",
    "\n",
    "        if query_id not in output:    \n",
    "            output[query_id] = [doc_id]\n",
    "        else:\n",
    "            output[query_id].append(doc_id)\n",
    "            \n",
    "    return output\n",
    "    \n",
    "\n",
    "qrels = read_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "assert len(qrels) == 52, \"There should be 52 queries with relevance judgements\"\n",
    "assert sum(len(j) for j in qrels.values()) == 796, \"There should be a total of 796 Relevance Judgements\"\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement the metrics below. \n",
    "\n",
    "**Note:** For a given query `query_id`, you can assume that documents *not* in `qrels[query_id]` are not relevant to `query_id`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "def recall_k(results, relevant_docs, k):\n",
    "    \"\"\"\n",
    "        Compute Recall@K\n",
    "        Input: \n",
    "            results: A sorted list of 2-tuples (document_id, score), with the most relevant document in the first position\n",
    "            relevant_docs: A set of relevant documents. \n",
    "            k: the cut-off\n",
    "        Output: Recall@K\n",
    "    \"\"\"\n",
    "    pred_doc_ids = [doc_id for doc_id, _ in results[:k]]\n",
    "    correct = len(set(relevant_docs) & set(pred_doc_ids))\n",
    "    \n",
    "    return correct/len(relevant_docs)\n",
    "    \n",
    "    \n",
    "    \n",
    "# TODO: Implement this! (10 points)\n",
    "def precision_k(results, relevant_docs, k):\n",
    "    \"\"\"\n",
    "        Compute Precision@K\n",
    "        Input: \n",
    "            results: A sorted list of 2-tuples (document_id, score), \n",
    "                    with the most relevant document in the first position\n",
    "            relevant_docs: A set of relevant documents. \n",
    "            k: the cut-off\n",
    "        Output: Precision@K\n",
    "    \"\"\"\n",
    "    \n",
    "    pred_doc_ids = [doc_id for doc_id, _ in results[:k]]\n",
    "    correct = len(set(relevant_docs) & set(pred_doc_ids))\n",
    "    \n",
    "    return correct / k\n",
    "    \n",
    "    \n",
    "\n",
    "# TODO: Implement this! (10 points)\n",
    "def average_precision(results, relevant_docs):\n",
    "    \"\"\"\n",
    "        Compute Average Precision (for a single query - the results are \n",
    "        averaged across queries to get MAP in the next few cells)\n",
    "        Hint: You can use the recall_k and precision_k functions here!\n",
    "        Input: \n",
    "            results: A sorted list of 2-tuples (document_id, score), with the most \n",
    "                    relevant document in the first position\n",
    "            relevant_docs: A set of relevant documents. \n",
    "        Output: Average Precision\n",
    "    \"\"\"\n",
    "    \n",
    "    ap = 0\n",
    "    \n",
    "    for i, (doc_id, _) in enumerate(results):\n",
    "        if doc_id in relevant_docs:\n",
    "            ap += precision_k(results, relevant_docs, i+1)\n",
    "            \n",
    "    return ap / len(relevant_docs)\n",
    "            \n",
    "\n",
    "\n",
    "# TODO: Implement this! (15 points)\n",
    "def err(results, relevant_docs):\n",
    "    \"\"\"\n",
    "        Compute the expected reciprocal rank.\n",
    "        Hint: https://dl.acm.org/doi/pdf/10.1145/1645953.1646033?download=true\n",
    "        Input: \n",
    "            results: A sorted list of 2-tuples (document_id, score), with the most \n",
    "                    relevant document in the first position\n",
    "            relevant_docs: A set of relevant documents. \n",
    "        Output: ERR\n",
    "        \n",
    "    \"\"\"\n",
    "    # g is a boolean array indicating relevance\n",
    "    g = np.array([doc_id in relevant_docs for doc_id, _ in results], dtype=int)\n",
    "    R_g = (np.power(2, g)-1) / np.power(2, g.max())\n",
    "    n = len(results)\n",
    "    prod = np.cumprod(1-R_g)\n",
    "    prod = np.insert(prod, 0, 1)[:-1]\n",
    "    err = 1 / np.arange(1, n+1) * prod * R_g\n",
    "    return err.sum()\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer the following questions*: \n",
    "- What are the main drawbacks of precision & recall?\n",
    "    - *TODO: Answer this!*\n",
    "    - Usually there is trade-off between precision and recall: are false positives or false negatives preferred for the problem setting? Furthermore, the scores on precision and recall are meaningless without the fraction of relevant documents in the collection, i.e. if almost none of the documents is relevant, the algorithm can predict non-relevance for all the documents and have a high precision. The other way around where most of the documents are relevant, and the model predicts all the documents as relevant, it has a high recall and precision, but has no discriminative power whatsoever. The most important drawback for information retrieval is that precision and recall do not take into account the ranking of the documents in the ranking (both consider the complete ranking, but not the order). This problem is partly solved by Precision@k and Recall@k, but even those metrics do not take into account the order within the top $k$.\n",
    "- What problems with Precision@K does Average Precision solve? \n",
    "    - *TODO: Answer this!*\n",
    "    - Precision@$k$ still does not take into account the order of the documents within the top $k$ of the ranking. Average Precision does, by taking the average over all the relevant documents, thereby rewarding highly ranked relevant documents and penalizing the low ranked relevant documents (in the whole ranking). \n",
    "- The CACM dataset has *binary* relevance judgements. However, a more suitable way of assigning judgements is to use graded relevance. Mention a metric which might be more suitable for a graded relevance, and briefly explain why. \n",
    "    - *TODO: Answer this!*\n",
    "    - An example of a metric that uses graded relevance is Discounted Cumulative Gain (DCG). In DCG, the relevance is based on the gain of examing the document, which is a graded scale. The relevance is scaled by a discount term, which is positively correlated with the rank $r$ (where the top document in the ranking has rank $r=1$).\n",
    "- Consider a text processing step: stemming. What effect does this have on metrics? (Hint: Try changing the pre-processing config and try it out!)\n",
    "    - *TODO: Answer this!*\n",
    "    - When we compare stemmed vs. non-stemmed text (by changing the 2 configs (both lowercase=True, remove_stopword=False, one with stemming and one without) and running the notebook) we see that all the search functions get the same or higher scores on all metrics in case of stemming, proving that stemming indeed is beneficiary for the search process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's define some metrics@k using [partial functions](https://docs.python.org/3/library/functools.html#functools.partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "recall_at_1 = partial(recall_k, k=1)\n",
    "recall_at_5 = partial(recall_k, k=5)\n",
    "recall_at_10 = partial(recall_k, k=10)\n",
    "precision_at_1 = partial(precision_k, k=1)\n",
    "precision_at_5 = partial(precision_k, k=5)\n",
    "precision_at_10 = partial(precision_k, k=10)\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following function evaluates a `search_fn` using the `metric_fn`. Note that the final number is averaged over all the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "def evaluate_search_fn(search_fn, metric_fn, index_set):\n",
    "    # build a dict query_id -> query \n",
    "    queries_by_id = dict((q[0], q[1]) for q in queries)\n",
    "    \n",
    "    metrics = np.zeros(len(qrels), dtype=np.float32)\n",
    "    for i, (query_id, relevant_docs) in enumerate(qrels.items()):\n",
    "        query = queries_by_id[query_id]\n",
    "        results = search_fn(query, index_set)\n",
    "        metrics[i] = metric_fn(results, relevant_docs)\n",
    "    \n",
    "    return metrics.mean()\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 1\n",
      "\tEvaluating Search Function: NaiveQL\n",
      "\t\tMetric: ERR: 0.014969581738114357\n",
      "\t\tMetric: MAP: 0.00882741529494524\n",
      "\t\tMetric: Recall@1: 0.0\n",
      "\t\tMetric: Recall@5: 0.0039143553003668785\n",
      "\t\tMetric: Recall@10: 0.0039143553003668785\n",
      "\t\tMetric: Precision@1: 0.0\n",
      "\t\tMetric: Precision@5: 0.011538461782038212\n",
      "\t\tMetric: Precision@10: 0.005769230891019106\n",
      "\n",
      "\tEvaluating Search Function: QL\n",
      "\t\tMetric: ERR: 0.014164397493004799\n",
      "\t\tMetric: MAP: 0.008394192904233932\n",
      "\t\tMetric: Recall@1: 0.0\n",
      "\t\tMetric: Recall@5: 0.004429464694112539\n",
      "\t\tMetric: Recall@10: 0.004429464694112539\n",
      "\t\tMetric: Precision@1: 0.0\n",
      "\t\tMetric: Precision@5: 0.011538461782038212\n",
      "\t\tMetric: Precision@10: 0.005769230891019106\n",
      "\n",
      "\tEvaluating Search Function: BM25\n",
      "\t\tMetric: ERR: 0.40404170751571655\n",
      "\t\tMetric: MAP: 0.23765285313129425\n",
      "\t\tMetric: Recall@1: 0.09718325734138489\n",
      "\t\tMetric: Recall@5: 0.22063495218753815\n",
      "\t\tMetric: Recall@10: 0.273042768239975\n",
      "\t\tMetric: Precision@1: 0.557692289352417\n",
      "\t\tMetric: Precision@5: 0.307692289352417\n",
      "\t\tMetric: Precision@10: 0.2230769544839859\n",
      "\n",
      "\tEvaluating Search Function: BOW\n",
      "\t\tMetric: ERR: 0.20937508344650269\n",
      "\t\tMetric: MAP: 0.09002292901277542\n",
      "\t\tMetric: Recall@1: 0.02086927741765976\n",
      "\t\tMetric: Recall@5: 0.08358566462993622\n",
      "\t\tMetric: Recall@10: 0.12322720140218735\n",
      "\t\tMetric: Precision@1: 0.21153846383094788\n",
      "\t\tMetric: Precision@5: 0.14999999105930328\n",
      "\t\tMetric: Precision@10: 0.12115384638309479\n",
      "\n",
      "\tEvaluating Search Function: TF-IDF\n",
      "\t\tMetric: ERR: 0.36417868733406067\n",
      "\t\tMetric: MAP: 0.23022380471229553\n",
      "\t\tMetric: Recall@1: 0.08936797082424164\n",
      "\t\tMetric: Recall@5: 0.1857801079750061\n",
      "\t\tMetric: Recall@10: 0.2577059864997864\n",
      "\t\tMetric: Precision@1: 0.48076921701431274\n",
      "\t\tMetric: Precision@5: 0.2769230902194977\n",
      "\t\tMetric: Precision@10: 0.20769232511520386\n",
      "\n",
      "Index: 2\n",
      "\tEvaluating Search Function: NaiveQL\n",
      "\t\tMetric: ERR: 0.010661772452294827\n",
      "\t\tMetric: MAP: 0.009257554076611996\n",
      "\t\tMetric: Recall@1: 0.0\n",
      "\t\tMetric: Recall@5: 0.0016025641234591603\n",
      "\t\tMetric: Recall@10: 0.0016025641234591603\n",
      "\t\tMetric: Precision@1: 0.0\n",
      "\t\tMetric: Precision@5: 0.003846153849735856\n",
      "\t\tMetric: Precision@10: 0.001923076924867928\n",
      "\n",
      "\tEvaluating Search Function: QL\n",
      "\t\tMetric: ERR: 0.014916603453457355\n",
      "\t\tMetric: MAP: 0.009760541841387749\n",
      "\t\tMetric: Recall@1: 0.0\n",
      "\t\tMetric: Recall@5: 0.004552739206701517\n",
      "\t\tMetric: Recall@10: 0.004552739206701517\n",
      "\t\tMetric: Precision@1: 0.0\n",
      "\t\tMetric: Precision@5: 0.011538461782038212\n",
      "\t\tMetric: Precision@10: 0.005769230891019106\n",
      "\n",
      "\tEvaluating Search Function: BM25\n",
      "\t\tMetric: ERR: 0.4758172631263733\n",
      "\t\tMetric: MAP: 0.32183507084846497\n",
      "\t\tMetric: Recall@1: 0.1259945034980774\n",
      "\t\tMetric: Recall@5: 0.24182432889938354\n",
      "\t\tMetric: Recall@10: 0.31476643681526184\n",
      "\t\tMetric: Precision@1: 0.6730769276618958\n",
      "\t\tMetric: Precision@5: 0.4153846204280853\n",
      "\t\tMetric: Precision@10: 0.313461571931839\n",
      "\n",
      "\tEvaluating Search Function: BOW\n",
      "\t\tMetric: ERR: 0.292279452085495\n",
      "\t\tMetric: MAP: 0.17512910068035126\n",
      "\t\tMetric: Recall@1: 0.06468385457992554\n",
      "\t\tMetric: Recall@5: 0.130839005112648\n",
      "\t\tMetric: Recall@10: 0.18029417097568512\n",
      "\t\tMetric: Precision@1: 0.38461539149284363\n",
      "\t\tMetric: Precision@5: 0.21153847873210907\n",
      "\t\tMetric: Precision@10: 0.18269230425357819\n",
      "\n",
      "\tEvaluating Search Function: TF-IDF\n",
      "\t\tMetric: ERR: 0.375860333442688\n",
      "\t\tMetric: MAP: 0.2811324894428253\n",
      "\t\tMetric: Recall@1: 0.11963681876659393\n",
      "\t\tMetric: Recall@5: 0.20895574986934662\n",
      "\t\tMetric: Recall@10: 0.26890847086906433\n",
      "\t\tMetric: Precision@1: 0.5\n",
      "\t\tMetric: Precision@5: 0.2807692289352417\n",
      "\t\tMetric: Precision@10: 0.24423076212406158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index_sets = {1, 2}\n",
    "\n",
    "list_of_metrics = [\n",
    "    (\"ERR\", err),\n",
    "    (\"MAP\", average_precision),\n",
    "    (\"Recall@1\",recall_at_1),\n",
    "    (\"Recall@5\", recall_at_5),\n",
    "    (\"Recall@10\", recall_at_10),\n",
    "    (\"Precision@1\", precision_at_1),\n",
    "    (\"Precision@5\", precision_at_5),\n",
    "    (\"Precision@10\", precision_at_10)]\n",
    "\n",
    "list_of_search_fns = [\n",
    "    (\"NaiveQL\", naive_ql_search),\n",
    "    (\"QL\", ql_search),\n",
    "    (\"BM25\", bm25_search),\n",
    "    (\"BOW\", bow_search),\n",
    "    (\"TF-IDF\", tfidf_search)\n",
    "]\n",
    "\n",
    "\n",
    "results = {}\n",
    "for index_set in index_sets:\n",
    "    results[index_set] = {}\n",
    "    print(f\"Index: {index_set}\")\n",
    "    for search_fn_name, search_fn in list_of_search_fns:\n",
    "        print(f\"\\tEvaluating Search Function: {search_fn_name}\")\n",
    "        results[index_set][search_fn_name] = {}\n",
    "        for metric_name, metric_fn in list_of_metrics:\n",
    "            r = evaluate_search_fn(search_fn, metric_fn, index_set).mean()\n",
    "            print(f\"\\t\\tMetric: {metric_name}: {r}\")\n",
    "            results[index_set][search_fn_name][metric_name] = r\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Results and Analysis (20 points)\n",
    "\n",
    "The `results` dictionary contains the results for all search functions we implemented. Plot the results in bar charts, with clear labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The bar plots made in this cell show the performance of all models on both indices side to side. \n",
    "\n",
    "my_colors = ['black','yellow', 'red', 'green', 'blue']\n",
    "\n",
    "# create labels for search functions\n",
    "search_fn_labels = [search_fn for search_fn in results[1]]\n",
    "metric_labels = [\"ERR\", \"MAP\", \"Recall@1\", \"Recall@5\", \"Recall@10\", \"Precision@1\", \"Precision@5\", \"Precision@10\"]\n",
    "\n",
    "# get results per index\n",
    "index1_results = results[1]\n",
    "values_1 = [[index1_results[search_fn][metric] for metric in index1_results[search_fn]] for search_fn in index1_results]\n",
    "# this is a list of lists in which the sublists are results per metric, for the search_fns in search_fn_labels\n",
    "results_per_metric_1 = [list(x) for x in zip(*values_1)] \n",
    "\n",
    "index2_results = results[2]\n",
    "values_2 = [[index2_results[search_fn][metric] for metric in index2_results[search_fn]] for search_fn in index2_results]\n",
    "# this is a list of lists in which the sublists are results per metric, for the search_fns in search_fn_labels\n",
    "results_per_metric_2 = [list(x) for x in zip(*values_2)] \n",
    "\n",
    "\n",
    "\n",
    "# define subplot\n",
    "fig, axs = plt.subplots(8, 2, figsize=(15, 7), sharey=True)\n",
    "\n",
    "for i, metric_values in enumerate(zip(results_per_metric_1, results_per_metric_2)):\n",
    "    \n",
    "    score_1, score_2 = metric_values\n",
    "    axs[i][0].bar(search_fn_labels, score_1, color=my_colors)\n",
    "    axs[i][0].set_title(metric_labels[i]+\" index 1\")\n",
    "    axs[i][0].set_ylabel(\"Score\")\n",
    "    axs[i][0].grid()\n",
    "    axs[i][1].bar(search_fn_labels, score_2, color=my_colors)\n",
    "    axs[i][1].set_title(metric_labels[i]+\" index 2\")\n",
    "    axs[i][1].grid()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.05, 0.8, 3])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a summary of what you observe in the results.\n",
    "You summary should compare results across the 2 indices and the methods being used. State what you expected to see in the results, followed by either supporting evidence *or* justify why the results did not support your expectations.      \n",
    "*Hint*: You may build upon the answers from the previous sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Answer this!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Above the scores on the different metrics for all the models are shown. First we will formulate a conclusion on the different search functions and their performance. Afterwards, the differences between the 2 indices will be dicsussed, and finally we will choose the best search engine based on these metrics.\n",
    "\n",
    "## Search function performance\n",
    "First of all we can see in the results that both the Query Likelihood (QL) models stay behind in terms of performance, and they perform worse than we expected. Also there is barely any improvement from the naive to the QL model that uses smoothing, which was expected. We suspect there might be a bug in the QL search algorithms, but did not manage to figure out what is causing the bad performance. \n",
    "\n",
    "-- hier iets zeggen over recall dan moeten we het aantal relevante documenten meenemen, de scores zijn laag maar misschien zijn er enorm veel relevante documenten. \n",
    "\n",
    "## Differences between indices\n",
    "In the second index, the words are stemmed and stop words are removed. The results show that this boosts performance of all models, on all metrics. From this, we can draw the conclusion that stemming and stopword removal indeed facilitate the search process. \n",
    "\n",
    "Overall, the $BM25$ model is superior on all performance metrics (on both indices), and benefits the most from text preprocessing (stemming and stop word removal). For the hyperparameters $k_1$ and $b$ we used typical values found in literature, so possibly tuning could improve the performance even further. Using the default model, the precision at 1 is quite high at $0.6$, and an average precision of $0.3$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
